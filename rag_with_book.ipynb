{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from langchain_chroma import Chroma\n",
    "\n",
    "loader = PyPDFLoader(\"book/ullman_the_complete_book.pdf\")\n",
    "pages = loader.load_and_split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pages = pages[:600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'58 CHAPTER 2. THE RELATIONAL MODEL OF DATA\\nExercise 2.4.7: Suppose relations R and S have n tuples and m tuples, re\\xad\\nspectively. Give the minimum and maximum numbers of tuples that the results \\nof the following expressions can have.\\na) R U S.\\nb) R tx S .\\nc) ac(R)  x S, for some condition C.\\nd) 7t l(R) —  S,  for some list of attributes L.\\nExercise 2.4.8: The semijoin  of relations R and S, written RIX S, is the set \\nof tuples t in R such that there is at least one tuple in S that agrees with t in \\nall attributes that R and S have in common. Give three different expressions \\nof relational algebra that are equivalent to R X  S.\\nExercise 2.4.9: The antisemijoin R  X  S is the set of tuples t in R that do \\nnot agree with any tuple of S in the attributes common to R and 5. Give an \\nexpression of relational algebra equivalent to R t x  S.\\nExercise 2.4.10: Let R be a relation with schema\\n(Ai,A 2 ,...  ,An,Bi,B2, ■ . . ,Bm)\\nand let 5 be a relation with schema (i?i,# 2,• •  ■  , Bm);  that is, the attributes \\nof S are a subset of the attributes of R. The quotient  of R and S, denoted \\nR-i- S,  is the set of tuples t over attributes A i, A2 ,...  ,An (i.e., the attributes \\nof R that are not attributes of S) such that for every tuple s in S, the tuple \\nts, consisting of the components of t for Ai,A2,... ,An  and the components \\nof s for BlyB2,... ,  Brn,  is a member of R. Give an expression of relational \\nalgebra, using the operators we have defined previously in this section, that is \\nequivalent to R-r- S.\\n2.5 Constraints on Relations\\nWe now take up the third important aspect of a data model: the ability to \\nrestrict the data that may be stored in a database. So far, we have seen only one \\nkind of constraint, the requirement that an attribute or attributes form a key \\n(Section 2.3.6). These and many other kinds of constraints can be expressed in \\nrelational algebra. In this section, we show how to express both key constraints \\nand “referential-integrity” constraints; the latter require that a value appearing \\nin one column of one relation also appear in some other column of the same \\nor a different relation. In Chapter 7, we see how SQL database systems can \\nenforce the same sorts of constraints as we can express in relational algebra.'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pages[100].page_content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "# from sentence_transformers import SentenceTransformer\n",
    "from langchain_community.embeddings.sentence_transformer import (\n",
    "    SentenceTransformerEmbeddings,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Project\\RAG_for_book\\rag_evn\\Lib\\site-packages\\huggingface_hub\\file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# create the open-source embedding function\n",
    "embedding_function = SentenceTransformerEmbeddings(model_name=\"all-MiniLM-L6-v2\")\n",
    "\n",
    "# load it into Chroma\n",
    "db = Chroma.from_documents(pages, embedding_function,persist_directory=\"./chroma_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='2.3. DEFINING  A RELATION SCHEMA IN  SQL 33\\nThe gender attribute has values that are a single letter, M  or F. Thus, we \\ncan safely use a single character as the type of this attribute. Finally, the \\nb irth d a te  attribute naturally deserves the data type D A TE. □\\n2.3.4 Modifying Relation Schemas\\nWe now know how to declare a table. But what if we need to change the schema \\nof the table after it has been in use for a long time and has many tuples in its \\ncurrent instance? We can remove the entire table, including all of its current \\ntuples, or we could change the schema by adding or deleting attributes.\\nWe can delete a relation R by the SQL statement:\\nD R O P TABLE R;\\nRelation R is no longer part of the database schema, and we can no longer \\naccess any of its tuples.\\nMore frequently than we would drop a relation that is part of a long-lived \\ndatabase, we may need to modify the schema of an existing relation. These \\nmodifications are done by a statement that begins with the keywords ALTER \\nTABLE and the name of the relation. We then have several options, the most \\nimportant of which are\\n1. A D D  followed by an attribute name and its data type.\\n2. D R O P followed by an attribute name.\\nE xam ple 2.4: Thus, for instance, we could modify the MovieStar relation by \\nadding an attribute phone with:\\nALTER TA BLE MovieStar A D D  phone CHAR(16);\\nAs a result, the MovieStar schema now has five attributes: the four mentioned \\nin Fig. 2.8 and the attribute phone, which is a fixed-length string of 16 bytes. \\nIn the actual relation, tuples would all have components for phone, but we \\nknow of no phone numbers to put there. Thus, the value of each of these \\ncomponents is set to the special null value,  N U LL. In Section 2.3.5, we shall see \\nhow it is possible to choose another “default” value to be used instead of N U L L  \\nfor unknown values.\\nAs another example, the A LTER TABLE statement:\\nALTER TA BLE MovieStar D R O P b irth d a te ;\\ndeletes the b irth d a te  attribute. As a result, the schema for MovieStar no \\nlonger has that attribute, and all tuples of the current MovieStar instance \\nhave the component for b irth d a te  deleted. □', metadata={'page': 69, 'source': 'book/ullman_the_complete_book.pdf'}),\n",
       " Document(page_content='40 CHAPTER 2. THE RELATIONAL MODEL OF DATA\\n1. R and S must have schemas with identical sets of attributes, and the \\ntypes (domains) for each attribute must be the same in R and S.\\n2. Before we compute the set-theoretic union, intersection, or difference of \\nsets of tuples, the columns of R and S must be ordered so that the order \\nof attributes is the same for both relations.\\nSometimes we would like to take the union, intersection, or difference of \\nrelations that have the same number of attributes, with corresponding domains, \\nbut that use different names for their attributes. If so, we may use the renaming \\noperator to be discussed in Section 2.4.11 to change the schema of one or both \\nrelations and give them the same set of attributes.\\nname address gender birthdate\\nCarrie Fisher 123 Maple St. ,  Hollywood F 9/9/99\\nMark Hamill 456 Oak Rd. ,  Brentwood M 8/8/88\\nRelation R\\nname address gender birthdate\\nCarrie Fisher 123 Maple St. ,  Hollywood F 9/9/99\\nHarrison Ford 789 Palm Dr., Beverly Hills M 7/7/77\\nRelation S\\nFigure 2.12: Two relations\\nExam ple 2.8: Suppose we have the two relations R and S, whose schemas \\nare both that of relation MovieStar Section 2.2.8. Current instances of R and \\nS are shown in Fig. 2.12. Then the union R U  S is\\nname address gender birthdate\\nCarrie Fisher 123 Maple St. ,  Hollywood F 9/9/99\\nMark Hamill 456 Oak Rd. ,  Brentwood M 8/8/88\\nHarrison Ford 789 Palm Dr., Beverly Hills M 7/7/77\\nNote that the two tuples for Carrie Fisher from the two relations appear only \\nonce in the result.\\nThe intersection R fl 5 is\\nname _________ | address ___________________| gender \\\\  birthdate\\nCarrie Fisher |  123 Maple St., Hollywood |  F |  9/9/99\\nNow, only the Carrie Fisher tuple appears, because only it is in both relations. \\nThe difference R —  S  is', metadata={'page': 76, 'source': 'book/ullman_the_complete_book.pdf'}),\n",
       " Document(page_content='Chapter 3\\nDesign Theory for  \\nRelational Databases\\nThere are many ways we could go about designing a relational database schema \\nfor an application. In Chapter 4 we shall see several high-level notations for \\ndescribing the structure of data and the ways in which these high-level designs \\ncan be converted into relations. We can also examine the requirements for a \\ndatabase and define relations directly, without going through a high-level inter\\xad\\nmediate stage. Whatever approach we use, it is common for an initial relational \\nschema to have room for improvement, especially by eliminating redundancy. \\nOften, the problems with a schema involve trying to combine too much into \\none relation.\\nFortunately, there is a well developed theory for relational databases: “de\\xad\\npendencies,” their implications for what makes a good relational database \\nschema, and what we can do about a schema if it has flaws. In this chapter, \\nwe first identify the problems that are caused in some relation schemas by the \\npresence of certain dependencies; these problems are referred to as “anomalies.”\\nOur discussion starts with “functional dependencies,” a generalization of the \\nidea of a key for a relation. We then use the notion of functional dependencies \\nto define normal forms for relation schemas. The impact of this theory, called \\n“normalization,” is that we decompose relations into two or more relations when \\nthat will remove anomalies. Next, we introduce “multivalued dependencies,” \\nwhich intuitively represent a condition where one or more attributes of a relation \\nare independent from one or more other attributes. These dependencies also \\nlead to normal forms and decomposition of relations to eliminate redundancy.\\n3.1 Functional Dependencies\\nThere is a design theory for relations that lets us examine a design carefully \\nand make improvements based on a few simple principles. The theory begins by\\n67', metadata={'page': 103, 'source': 'book/ullman_the_complete_book.pdf'}),\n",
       " Document(page_content='4.5. FROM E /R  DIAGRAMS TO RELATIONAL DESIGNS 157\\n4.5 From E /R  Diagrams to Relational Designs\\nTo a first approximation, converting an E /E  design to a relational database \\nschema is straightforward:\\n• Turn each entity set into a relation with the same set of attributes, and\\n• Replace a relationship by a relation whose attributes are the keys for the \\nconnected entity sets.\\nWhile these two rules cover much of the ground, there are also several special \\nsituations that we need to deal with, including:\\n1. Weak entity sets cannot be translated straightforwardly to relations.\\n2. “Isa” relationships and subclasses require careful treatment.\\n3. Sometimes, we do well to combine two relations, especially the relation for \\nan entity set E and the relation that comes from a many-one relationship \\nfrom E to some other entity set.\\n4.5.1 Prom Entity Sets to Relations\\nLet us first consider entity sets that are not weak. We shall take up the mod\\xad\\nifications needed to accommodate weak entity sets in Section 4.5.4. For each \\nnon-weak entity set, we shall create a relation of the same name and with the \\nsame set of attributes. This relation will not have any indication of the rela\\xad\\ntionships in which the entity set participates; we’ll handle relationships with \\nseparate relations, as discussed in Section 4.5.2.\\nE xam ple 4.24: Consider the three entity sets Movies, Stars  and Studios  from \\nFig. 4.17, which we reproduce here as Fig. 4.23. The attributes for the Movies  \\nentity set are title, year, length,  and genre.  As a result, this relation Movies \\nlooks just like the relation Movies  of Fig. 2.1 with which we began Section 2.2.\\nNext, consider the entity set Stars  from Fig. 4.23. There are two attributes, \\nname  and address.  Thus, we would expect the corresponding Stars relation to \\nhave schema Stars (name, address) and for\\nname address\\nCarrie Fisher \\nMark Hamill \\nHarrison Ford123 Maple St \\n456 Oak Rd.,  \\n789 Palm Dr.. ,  Hollywood \\nBrentwood \\n,  Beverly Hills\\nto be a typical instance. □', metadata={'page': 193, 'source': 'book/ullman_the_complete_book.pdf'})]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# query it\n",
    "query = \"Modifying Relation Schemas\"\n",
    "docs = db.similarity_search(query)\n",
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Chroma in module langchain_chroma.vectorstores object:\n",
      "\n",
      "class Chroma(langchain_core.vectorstores.VectorStore)\n",
      " |  Chroma(collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.ClientAPI]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None, create_collection_if_not_exists: 'Optional[bool]' = True) -> 'None'\n",
      " |  \n",
      " |  `ChromaDB` vector store.\n",
      " |  \n",
      " |  To use, you should have the ``chromadb`` python package installed.\n",
      " |  \n",
      " |  Example:\n",
      " |      .. code-block:: python\n",
      " |  \n",
      " |              from langchain_chroma import Chroma\n",
      " |              from langchain_openai import OpenAIEmbeddings\n",
      " |  \n",
      " |              embeddings = OpenAIEmbeddings()\n",
      " |              vectorstore = Chroma(\"langchain_store\", embeddings)\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Chroma\n",
      " |      langchain_core.vectorstores.VectorStore\n",
      " |      abc.ABC\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, collection_name: 'str' = 'langchain', embedding_function: 'Optional[Embeddings]' = None, persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, collection_metadata: 'Optional[Dict]' = None, client: 'Optional[chromadb.ClientAPI]' = None, relevance_score_fn: 'Optional[Callable[[float], float]]' = None, create_collection_if_not_exists: 'Optional[bool]' = True) -> 'None'\n",
      " |      Initialize with a Chroma client.\n",
      " |  \n",
      " |  add_images(self, uris: 'List[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more images through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          uris List[str]: File path to the image.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added images.\n",
      " |  \n",
      " |  add_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (Iterable[str]): Texts to add to the vectorstore.\n",
      " |          metadatas (Optional[List[dict]], optional): Optional list of metadatas.\n",
      " |          ids (Optional[List[str]], optional): Optional list of IDs.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  delete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'None'\n",
      " |      Delete by vector IDs.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |  \n",
      " |  delete_collection(self) -> 'None'\n",
      " |      Delete the collection.\n",
      " |  \n",
      " |  encode_image(self, uri: 'str') -> 'str'\n",
      " |      Get base64 string from image URI.\n",
      " |  \n",
      " |  get(self, ids: 'Optional[OneOrMany[ID]]' = None, where: 'Optional[Where]' = None, limit: 'Optional[int]' = None, offset: 'Optional[int]' = None, where_document: 'Optional[WhereDocument]' = None, include: 'Optional[List[str]]' = None) -> 'Dict[str, Any]'\n",
      " |      Gets the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: The ids of the embeddings to get. Optional.\n",
      " |          where: A Where type dict used to filter results by.\n",
      " |                 E.g. `{\"color\" : \"red\", \"price\": 4.20}`. Optional.\n",
      " |          limit: The number of documents to return. Optional.\n",
      " |          offset: The offset to start returning results from.\n",
      " |                  Useful for paging results with limit. Optional.\n",
      " |          where_document: A WhereDocument type dict used to filter by the documents.\n",
      " |                          E.g. `{$contains: \"hello\"}`. Optional.\n",
      " |          include: A list of what to include in the results.\n",
      " |                   Can contain `\"embeddings\"`, `\"metadatas\"`, `\"documents\"`.\n",
      " |                   Ids are always included.\n",
      " |                   Defaults to `[\"metadatas\", \"documents\"]`. Optional.\n",
      " |  \n",
      " |  max_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  max_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding: Embedding to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  similarity_search(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Run similarity search with Chroma.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Document]: List of documents most similar to the query text.\n",
      " |  \n",
      " |  similarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      Returns:\n",
      " |          List of Documents most similar to the query vector.\n",
      " |  \n",
      " |  similarity_search_by_vector_with_relevance_scores(self, embedding: 'List[float]', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs most similar to embedding vector and similarity score.\n",
      " |      \n",
      " |      Args:\n",
      " |          embedding (List[float]): Embedding to look up documents similar to.\n",
      " |          k (int): Number of Documents to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  similarity_search_with_score(self, query: 'str', k: 'int' = 4, filter: 'Optional[Dict[str, str]]' = None, where_document: 'Optional[Dict[str, str]]' = None, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with Chroma with distance.\n",
      " |      \n",
      " |      Args:\n",
      " |          query (str): Query text to search for.\n",
      " |          k (int): Number of results to return. Defaults to 4.\n",
      " |          filter (Optional[Dict[str, str]]): Filter by metadata. Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[Tuple[Document, float]]: List of documents most similar to\n",
      " |          the query text and cosine distance in float for each.\n",
      " |          Lower score represents more similarity.\n",
      " |  \n",
      " |  update_document(self, document_id: 'str', document: 'Document') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          document_id (str): ID of the document to update.\n",
      " |          document (Document): Document to update.\n",
      " |  \n",
      " |  update_documents(self, ids: 'List[str]', documents: 'List[Document]') -> 'None'\n",
      " |      Update a document in the collection.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids (List[str]): List of ids of the document to update.\n",
      " |          documents (List[Document]): List of documents to update.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods defined here:\n",
      " |  \n",
      " |  from_documents(documents: 'List[Document]', embedding: 'Optional[Embeddings]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.ClientAPI]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a list of documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          documents (List[Document]): List of documents to add to the vectorstore.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  from_texts(texts: 'List[str]', embedding: 'Optional[Embeddings]' = None, metadatas: 'Optional[List[dict]]' = None, ids: 'Optional[List[str]]' = None, collection_name: 'str' = 'langchain', persist_directory: 'Optional[str]' = None, client_settings: 'Optional[chromadb.config.Settings]' = None, client: 'Optional[chromadb.ClientAPI]' = None, collection_metadata: 'Optional[Dict]' = None, **kwargs: 'Any') -> 'Chroma' from abc.ABCMeta\n",
      " |      Create a Chroma vectorstore from a raw documents.\n",
      " |      \n",
      " |      If a persist_directory is specified, the collection will be persisted there.\n",
      " |      Otherwise, the data will be ephemeral in-memory.\n",
      " |      \n",
      " |      Args:\n",
      " |          texts (List[str]): List of texts to add to the collection.\n",
      " |          collection_name (str): Name of the collection to create.\n",
      " |          persist_directory (Optional[str]): Directory to persist the collection.\n",
      " |          embedding (Optional[Embeddings]): Embedding function. Defaults to None.\n",
      " |          metadatas (Optional[List[dict]]): List of metadatas. Defaults to None.\n",
      " |          ids (Optional[List[str]]): List of document IDs. Defaults to None.\n",
      " |          client_settings (Optional[chromadb.config.Settings]): Chroma client settings\n",
      " |          collection_metadata (Optional[Dict]): Collection configurations.\n",
      " |                                                Defaults to None.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Chroma: Chroma vectorstore.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties defined here:\n",
      " |  \n",
      " |  embeddings\n",
      " |      Access the query embedding object if available.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  __annotations__ = {}\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async aadd_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async aadd_texts(self, texts: 'Iterable[str]', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more texts through the embeddings and add to the vectorstore.\n",
      " |  \n",
      " |  add_documents(self, documents: 'List[Document]', **kwargs: 'Any') -> 'List[str]'\n",
      " |      Run more documents through the embeddings and add to the vectorstore.\n",
      " |      \n",
      " |      Args:\n",
      " |          documents (List[Document]: Documents to add to the vectorstore.\n",
      " |      \n",
      " |      Returns:\n",
      " |          List[str]: List of IDs of the added texts.\n",
      " |  \n",
      " |  async adelete(self, ids: 'Optional[List[str]]' = None, **kwargs: 'Any') -> 'Optional[bool]'\n",
      " |      Delete by vector ID or other criteria.\n",
      " |      \n",
      " |      Args:\n",
      " |          ids: List of ids to delete.\n",
      " |          **kwargs: Other keyword arguments that subclasses might use.\n",
      " |      \n",
      " |      Returns:\n",
      " |          Optional[bool]: True if deletion is successful,\n",
      " |          False otherwise, None if not implemented.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search(self, query: 'str', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |      \n",
      " |      Maximal marginal relevance optimizes for similarity to query AND diversity\n",
      " |      among selected documents.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: Text to look up documents similar to.\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          fetch_k: Number of Documents to fetch to pass to MMR algorithm.\n",
      " |          lambda_mult: Number between 0 and 1 that determines the degree\n",
      " |                      of diversity among the results with 0 corresponding\n",
      " |                      to maximum diversity and 1 to minimum diversity.\n",
      " |                      Defaults to 0.5.\n",
      " |      Returns:\n",
      " |          List of Documents selected by maximal marginal relevance.\n",
      " |  \n",
      " |  async amax_marginal_relevance_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, fetch_k: 'int' = 20, lambda_mult: 'float' = 0.5, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs selected using the maximal marginal relevance.\n",
      " |  \n",
      " |  as_retriever(self, **kwargs: 'Any') -> 'VectorStoreRetriever'\n",
      " |      Return VectorStoreRetriever initialized from this VectorStore.\n",
      " |      \n",
      " |      Args:\n",
      " |          search_type (Optional[str]): Defines the type of search that\n",
      " |              the Retriever should perform.\n",
      " |              Can be \"similarity\" (default), \"mmr\", or\n",
      " |              \"similarity_score_threshold\".\n",
      " |          search_kwargs (Optional[Dict]): Keyword arguments to pass to the\n",
      " |              search function. Can include things like:\n",
      " |                  k: Amount of documents to return (Default: 4)\n",
      " |                  score_threshold: Minimum relevance threshold\n",
      " |                      for similarity_score_threshold\n",
      " |                  fetch_k: Amount of documents to pass to MMR algorithm (Default: 20)\n",
      " |                  lambda_mult: Diversity of results returned by MMR;\n",
      " |                      1 for minimum diversity and 0 for maximum. (Default: 0.5)\n",
      " |                  filter: Filter by document metadata\n",
      " |      \n",
      " |      Returns:\n",
      " |          VectorStoreRetriever: Retriever class for VectorStore.\n",
      " |      \n",
      " |      Examples:\n",
      " |      \n",
      " |      .. code-block:: python\n",
      " |      \n",
      " |          # Retrieve more documents with higher diversity\n",
      " |          # Useful if your dataset has many similar documents\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 6, 'lambda_mult': 0.25}\n",
      " |          )\n",
      " |      \n",
      " |          # Fetch more documents for the MMR algorithm to consider\n",
      " |          # But only return the top 5\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"mmr\",\n",
      " |              search_kwargs={'k': 5, 'fetch_k': 50}\n",
      " |          )\n",
      " |      \n",
      " |          # Only retrieve documents that have a relevance score\n",
      " |          # Above a certain threshold\n",
      " |          docsearch.as_retriever(\n",
      " |              search_type=\"similarity_score_threshold\",\n",
      " |              search_kwargs={'score_threshold': 0.8}\n",
      " |          )\n",
      " |      \n",
      " |          # Only get the single most similar document from the dataset\n",
      " |          docsearch.as_retriever(search_kwargs={'k': 1})\n",
      " |      \n",
      " |          # Use a filter to only retrieve documents from a specific paper\n",
      " |          docsearch.as_retriever(\n",
      " |              search_kwargs={'filter': {'paper_title':'GPT-4 Technical Report'}}\n",
      " |          )\n",
      " |  \n",
      " |  async asearch(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  async asimilarity_search(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query.\n",
      " |  \n",
      " |  async asimilarity_search_by_vector(self, embedding: 'List[float]', k: 'int' = 4, **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to embedding vector.\n",
      " |  \n",
      " |  async asimilarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1], asynchronously.\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  async asimilarity_search_with_score(self, *args: 'Any', **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Run similarity search with distance asynchronously.\n",
      " |  \n",
      " |  search(self, query: 'str', search_type: 'str', **kwargs: 'Any') -> 'List[Document]'\n",
      " |      Return docs most similar to query using specified search type.\n",
      " |  \n",
      " |  similarity_search_with_relevance_scores(self, query: 'str', k: 'int' = 4, **kwargs: 'Any') -> 'List[Tuple[Document, float]]'\n",
      " |      Return docs and relevance scores in the range [0, 1].\n",
      " |      \n",
      " |      0 is dissimilar, 1 is most similar.\n",
      " |      \n",
      " |      Args:\n",
      " |          query: input text\n",
      " |          k: Number of Documents to return. Defaults to 4.\n",
      " |          **kwargs: kwargs to be passed to similarity search. Should include:\n",
      " |              score_threshold: Optional, a floating point value between 0 to 1 to\n",
      " |                  filter the resulting set of retrieved docs\n",
      " |      \n",
      " |      Returns:\n",
      " |          List of Tuples of (doc, similarity_score)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Class methods inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  async afrom_documents(documents: 'List[Document]', embedding: 'Embeddings', **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from documents and embeddings.\n",
      " |  \n",
      " |  async afrom_texts(texts: 'List[str]', embedding: 'Embeddings', metadatas: 'Optional[List[dict]]' = None, **kwargs: 'Any') -> 'VST' from abc.ABCMeta\n",
      " |      Return VectorStore initialized from texts and embeddings.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from langchain_core.vectorstores.VectorStore:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      "\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rag_evn",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
